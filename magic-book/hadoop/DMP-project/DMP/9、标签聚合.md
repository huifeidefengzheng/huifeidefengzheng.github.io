#### 2.15.5.6：标签聚合

虽然目前为止，标签抽取出来了，也进行了统一用户识别，但是还可能出现另一种问题，例如：

一个用户产生了两条日志：(简写版本)

| 用户识别码                     | 标签                           |
| ------------------------------ | ------------------------------ |
| (MAC:52:54:00:37:94:2D,0)      | (K大众汽车,1.92)(K二手车,1.92) |
| (ANDROIDID:APZWRJWTAHUTJTXD,0) | (K德国汽车,1.92)(K二手车,1.92) |

经过图计算进行统一用户识别之后:

| 用户识别码                                              | 标签                                                         |
| ------------------------------------------------------- | ------------------------------------------------------------ |
| (MAC:52:54:00:37:94:2D,0)(ANDROIDID:APZWRJWTAHUTJTXD,0) | (K大众汽车,1.92)**<u>(K二手车,1.92)(K二手车,1.92)</u>**(K德国汽车,1.92) |

从上面表格中，我们可以看出，(K二手车,1.92)这个标签重复了，但是权重值还是1.92，这样后续广告主根据标签选择受众目的时候，不一定是权重值最高的，会导致广告的推荐并不是精准的

因此，需要对统一用户识别出来的标签进一步聚合----标签聚合

##### 2.15.5.6.1：在TagProcess中添加聚合的调用代码

```scala
//标签聚合
    val currentDayTags: RDD[(VertexId, (List[String], Map[String, Double]))] = TagAgg.agg(graphRdd)
```

##### 2.15.5.6.2：编写聚合代码TagAgg

##### 

```scala
package agg

import org.apache.spark.graphx.VertexId
import org.apache.spark.rdd.RDD

/**
  * 标签聚合
  */
object TagAgg {

  def agg(graphRdd: RDD[(VertexId, (VertexId, (List[String], Map[String, Double])))]):RDD[(VertexId, (List[String], Map[String, Double]))]={

    val aggRdd = graphRdd.map {
      case (userId, (aggid, (allUserIds, tags))) =>
        (aggid, (allUserIds, tags))
    }
    //[(1,(userIds,tags)),(1,(userIds,tags)),(1,(userIds,tags))] .reduceByKey
    val result: RDD[(VertexId, (List[String], Map[String, Double]))] = aggRdd.reduceByKey((left, right) => {

      val leftUserIds = left._1

      val rightUserIds = right._1

      //用户所有标识
      val allUserIds = (leftUserIds ++ rightUserIds).distinct

      val leftTags = left._2

      val rightTags = right._2
      //[(BA_永昌,1.0),(BA_永昌,1.0)] =>[(BA_永昌,[(BA_永昌,1.0),(BA_永昌,1.0)])]
      val groupTags: Map[String, List[(String, Double)]] = (leftTags.toList ++ rightTags.toList).groupBy(_._1)

      val allTags: Map[String, Double] = groupTags.map {
        case (tagName, tags) =>
          (tagName, tags.map(_._2).sum)
      }
      (allUserIds, allTags)
    })
    result
  }
}

```

#### 